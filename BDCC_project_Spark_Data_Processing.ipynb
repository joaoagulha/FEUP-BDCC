{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BDCC_project_Spark_Data_Processing.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xm9K0GA_mj4q",
        "colab_type": "text"
      },
      "source": [
        "# BDCC project - Spark data processing\n",
        "\n",
        "**[Big Data and Cloud Computing](https://www.dcc.fc.up.pt/~edrdo/aulas/bdcc), Eduardo R. B. Marques, DCC/FCUP**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLs-2tHZVdAE",
        "colab_type": "text"
      },
      "source": [
        "## Spark setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94Ts396zKTcr",
        "colab_type": "code",
        "outputId": "f98dff2b-8f4d-4171-bae7-1e0d3ba26b91",
        "cellView": "both",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        }
      },
      "source": [
        "\n",
        "def setupSpark():\n",
        "  # Spark needs to run with Java 8 ... \n",
        "  !pip install -q findspark\n",
        "  !apt-get install openjdk-8-jdk-headless > /dev/null\n",
        "  !echo 2 | update-alternatives --config java > /dev/null\n",
        "  # !java -version\n",
        "  import os, findspark\n",
        "  os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-8-openjdk-amd64'\n",
        "  # !echo JAVA_HOME=$JAVA_HOME\n",
        "  !pip install -q pyspark\n",
        "  findspark.init(spark_home='/usr/local/lib/python3.6/dist-packages/pyspark')\n",
        "  !pyspark --version\n",
        "\n",
        "setupSpark()\n",
        "\n",
        "from pyspark import SparkContext\n",
        "from pyspark.sql import SparkSession\n",
        "    \n",
        "spark = SparkSession\\\n",
        "        .builder\\\n",
        "        .master('local[*]')\\\n",
        "        .getOrCreate()\n",
        "sc = spark.sparkContext"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Welcome to\n",
            "      ____              __\n",
            "     / __/__  ___ _____/ /__\n",
            "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
            "   /___/ .__/\\_,_/_/ /_/\\_\\   version 2.4.5\n",
            "      /_/\n",
            "                        \n",
            "Using Scala version 2.11.12, OpenJDK 64-Bit Server VM, 1.8.0_242\n",
            "Branch HEAD\n",
            "Compiled by user centos on 2020-02-02T19:38:06Z\n",
            "Revision cee4ecbb16917fa85f02c635925e2687400aa56b\n",
            "Url https://gitbox.apache.org/repos/asf/spark.git\n",
            "Type --help for more information.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OARapl23eWy5",
        "colab_type": "code",
        "outputId": "a491e5d6-5769-49cd-dd6c-97b2deaee520",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5_EiJeM8fyLw",
        "colab_type": "code",
        "outputId": "130846a0-164f-4bd0-bd88-02fb6ac8ea06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/My Drive/bdcc-colab.json' \n",
        "!echo $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/bdcc-colab.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RK81bxtWf2RE",
        "colab_type": "code",
        "outputId": "2fa6ccf5-b4e3-4338-9f9b-fe8bcdc2ced5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from google.cloud import storage\n",
        "\n",
        "storage_client = storage.Client()\n",
        "buckets = storage_client.list_buckets()\n",
        "print('-- List of buckets in project \\\"' + storage_client.project + '\\\"')\n",
        "\n",
        "for b in buckets:\n",
        "  print(b.name)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-- List of buckets in project \"bdcc20-p1\"\n",
            "bdcc20-movie_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CpEwoJd4T998",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 330
        },
        "outputId": "184e9758-62d2-45a7-9209-87b7b7ef16f0"
      },
      "source": [
        "# To enable the GPU access Edit > Notebook settings and set the Hardware accelerator to GPU.\n",
        "\n",
        "%tensorflow_version 2.x \n",
        "import tensorflow as tf\n",
        "\n",
        "print(\"GPU device: \" + tf.test.gpu_device_name())\n",
        "\n",
        "from tensorflow.python.client import device_lib\n",
        "\n",
        "tf_devices = device_lib.list_local_devices()\n",
        "\n",
        "for x in tf_devices:\n",
        "  print('------')\n",
        "  print(x)\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU device: \n",
            "------\n",
            "name: \"/device:CPU:0\"\n",
            "device_type: \"CPU\"\n",
            "memory_limit: 268435456\n",
            "locality {\n",
            "}\n",
            "incarnation: 2734688099200934691\n",
            "\n",
            "------\n",
            "name: \"/device:XLA_CPU:0\"\n",
            "device_type: \"XLA_CPU\"\n",
            "memory_limit: 17179869184\n",
            "locality {\n",
            "}\n",
            "incarnation: 10272481926892409763\n",
            "physical_device_desc: \"device: XLA_CPU device\"\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BWuVMPq-VJug",
        "colab_type": "text"
      },
      "source": [
        "## Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6QYyjiwTciH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "\n",
        "#@markdown ---\n",
        "DEBUG = True #@param {type: \"boolean\"} \n",
        "PROJECT_ID = 'bdcc20-p1'  #@param {type: \"string\"}\n",
        "INPUT_BUCKET = 'bdcc20-movie_data/bdcc1920_project_datasets' #@param {type: \"string\"}\n",
        "DATASET = 'tiny1' #@param [\"tiny1\", \"tiny2\", \"tiny3\", \"tiny4\", \"medium1\", \"medium2\", \"medium3\", \"medium4\", \"large1\", \"large2\", \"large3\", \"large4\", \"large5\"] {allow-input: true}\n",
        "OUTPUT_BUCKET = 'bdcc20-movie_data/bdcc1920_project_outputs' #@param {type: \"string\"}\n",
        "OUTPUT_ZIP_FILE = 'output.zip' #@param {type: \"string\"}\n",
        "COPY_PARQUET_FILES_TO_OUTPUT_BUCKET = True #@param {type: \"boolean\"} \n",
        "MIN_TF_IDF = 0.1 #@param {type:\"slider\", min:0, max:1, step:0.05}\n",
        "SEND_PUBSUB_MESSAGE = True #@param {type: \"boolean\"} \n",
        "PUBSUB_TOPIC = 'dispatcher' #@param {type: \"string\"}\n",
        "#@markdown ---\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYpLKlN_WVQK",
        "colab_type": "text"
      },
      "source": [
        "## Authenticate to GCP"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JBUnFD7WYhJ",
        "colab_type": "code",
        "outputId": "6f4253c1-bbfc-4dbe-9304-22b0c6dec7c8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        }
      },
      "source": [
        "# The authentication method \n",
        "def google_colab_authenticate(projectId, keyFile=None, debug=True):  \n",
        "    import os\n",
        "    from google.colab import auth\n",
        "    if keyFile == None:\n",
        "      keyFile='/content/bdcc-colab.json'\n",
        "    if os.access(keyFile,os.R_OK):\n",
        "      if debug:\n",
        "        print('Using key file \"%s\"' % keyFile)\n",
        "      os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '%s' % keyFile\n",
        "      os.environ['GCP_PROJECT'] = 'bdcc20-p1' \n",
        "      os.environ['GCP_ACCOUNT'] = 'bdcc-colab@' + projectId + '.iam.gserviceaccount.com'\n",
        "      !gcloud auth activate-service-account --key-file=\"$GOOGLE_APPLICATION_CREDENTIALS\" --project=\"$GCP_PROJECT\"\n",
        "    else:\n",
        "      if debug:\n",
        "        print('No key file given. You may be redirected to the verification code procedure.')\n",
        "      auth.authenticate_user()\n",
        "      !gcloud config set project $projectId\n",
        "    !gcloud info | grep -e Account -e Project\n",
        "\n",
        "# Copy key file from Google Drive if available \n",
        "# to a path without spaces (it usually creates problems)\n",
        "!test -f \"/content/drive/My Drive/bdcc-colab.json\" && cp \"/content/drive/My Drive/bdcc-colab.json\" /content/bdcc-colab.json\n",
        "\n",
        "google_colab_authenticate(PROJECT_ID)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using key file \"/content/bdcc-colab.json\"\n",
            "Activated service account credentials for: [bdcc-cloud@bdcc20-p1.iam.gserviceaccount.com]\n",
            "Account: [bdcc-cloud@bdcc20-p1.iam.gserviceaccount.com]\n",
            "Project: [bdcc20-p1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9BaWKW-XjHZ",
        "colab_type": "text"
      },
      "source": [
        "## Transfer dataset files (if necessary) from GCS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pek32UH5X0e0",
        "colab_type": "code",
        "outputId": "8d195b65-2fcb-43ce-a426-bacca971048f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "!test -d $DATASET || gsutil -m cp -r gs://\"$INPUT_BUCKET\"/\"$DATASET\" .\n",
        "!du --human $DATASET"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24K\ttiny1/genres.parquet\n",
            "104K\ttiny1/output/tfidf.parquet\n",
            "176K\ttiny1/output/jaccardIndex.parquet\n",
            "88K\ttiny1/output/movies_agg.parquet\n",
            "372K\ttiny1/output\n",
            "16K\ttiny1/tags.parquet\n",
            "24K\ttiny1/actors.parquet\n",
            "16K\ttiny1/movies.parquet\n",
            "16K\ttiny1/ratings.parquet\n",
            "524K\ttiny1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tZmcj26dHJ5X",
        "colab_type": "text"
      },
      "source": [
        "## Parquet file read/write methods\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RpaXsmgV-Wi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def readCSV(file):\n",
        "    global spark\n",
        "    if DEBUG:\n",
        "       print('==> Reading ' + file)\n",
        "    if DEBUG:\n",
        "      df.printSchema()\n",
        "      df.show(10)\n",
        "    return spark.read.csv(file, inferSchema=True, header=True)\n",
        "\n",
        "def readParquet(file):\n",
        "    global spark\n",
        "    if DEBUG:\n",
        "       print('==> Reading ' + file)\n",
        "    df = spark.read.parquet(file)\n",
        "    if DEBUG:\n",
        "      df.printSchema()\n",
        "      df.show(10)\n",
        "    return df\n",
        " \n",
        "def writeParquet(df,path):\n",
        "    if DEBUG:\n",
        "        print('==> Writing ' + path)\n",
        "    !rm -fr $path\n",
        "    df.write.parquet(path, mode='overwrite')\n",
        "\n",
        "\n",
        "def readFile(file, format):\n",
        "  file += '.'\n",
        "  file += format\n",
        "  return (readParquet(file) if format == 'parquet' \n",
        "          else readCSV(file))\n",
        "\n",
        "def loadMovieLensData(path, format='parquet'):\n",
        "    actors = readFile(path +'actors', format)\n",
        "    genres = readFile(path +'genres', format)\n",
        "    movies = readFile(path +'movies', format)\n",
        "    ratings = readFile(path +'ratings', format)\n",
        "    tags = readFile(path +'tags', format)\n",
        "    return actors, genres, movies, ratings, tags"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGiru5hTTu97",
        "colab_type": "text"
      },
      "source": [
        "## Load input dataset from Parquet files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U9Fa3P98Tt5l",
        "colab_type": "code",
        "outputId": "612a17c6-e6d0-4136-c396-0c9d4cb3f0c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "bucket = 'gs://bdcc20-movie_data/' \n",
        "path = 'bdcc1920_project_datasets/'\n",
        "dataset = 'tiny1/'\n",
        "fullPath = bucket + path + dataset\n",
        "\n",
        "actors, genres, movies, ratings, tags = \\\n",
        "  loadMovieLensData(DATASET+'/')\n",
        "\"\"\"\n",
        "movies =  readParquet(DATASET + '/movies.parquet')\n",
        "actors =  readParquet(DATASET + '/actors.parquet')\n",
        "genres =  readParquet(DATASET + '/genres.parquet')\n",
        "ratings = readParquet(DATASET + '/ratings.parquet')\n",
        "tags =    readParquet(DATASET + '/tags.parquet')\n",
        "\"\"\""
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==> Reading tiny1/actors.parquet\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            "\n",
            "+-------+--------------+\n",
            "|movieId|          name|\n",
            "+-------+--------------+\n",
            "|      1|     Tim Allen|\n",
            "|      1|   Don Rickles|\n",
            "|      1|    Jim Varney|\n",
            "|      1|     Tom Hanks|\n",
            "|      2| Kirsten Dunst|\n",
            "|      2|Robin Williams|\n",
            "|      2| Jonathan Hyde|\n",
            "|      2|   Bonnie Hunt|\n",
            "|      3|   Jack Lemmon|\n",
            "|      3|Walter Matthau|\n",
            "+-------+--------------+\n",
            "only showing top 10 rows\n",
            "\n",
            "==> Reading tiny1/genres.parquet\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- genre: string (nullable = true)\n",
            "\n",
            "+-------+---------+\n",
            "|movieId|    genre|\n",
            "+-------+---------+\n",
            "|      1|Adventure|\n",
            "|      1|Animation|\n",
            "|      1| Children|\n",
            "|      1|   Comedy|\n",
            "|      1|  Fantasy|\n",
            "|      2|Adventure|\n",
            "|      2| Children|\n",
            "|      2|  Fantasy|\n",
            "|      3|   Comedy|\n",
            "|      3|  Romance|\n",
            "+-------+---------+\n",
            "only showing top 10 rows\n",
            "\n",
            "==> Reading tiny1/movies.parquet\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- imdbId: integer (nullable = true)\n",
            "\n",
            "+-------+--------------------+----+------+\n",
            "|movieId|               title|year|imdbId|\n",
            "+-------+--------------------+----+------+\n",
            "|      1|           Toy Story|1995|114709|\n",
            "|      2|             Jumanji|1995|113497|\n",
            "|      3|    Grumpier Old Men|1995|113228|\n",
            "|      4|   Waiting to Exhale|1995|114885|\n",
            "|      5|Father of the Bri...|1995|113041|\n",
            "|      6|                Heat|1995|113277|\n",
            "|      7|             Sabrina|1995|114319|\n",
            "|      8|        Tom and Huck|1995|112302|\n",
            "|      9|        Sudden Death|1995|114576|\n",
            "|     10|           GoldenEye|1995|113189|\n",
            "+-------+--------------------+----+------+\n",
            "\n",
            "==> Reading tiny1/ratings.parquet\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- rating: double (nullable = true)\n",
            "\n",
            "+-------+------+------+\n",
            "|movieId|userId|rating|\n",
            "+-------+------+------+\n",
            "|      1|     1|   4.0|\n",
            "|      3|     1|   4.0|\n",
            "|      6|     1|   4.0|\n",
            "|      1|     5|   4.0|\n",
            "|      2|     6|   4.0|\n",
            "|      3|     6|   5.0|\n",
            "|      4|     6|   3.0|\n",
            "|      5|     6|   5.0|\n",
            "|      6|     6|   4.0|\n",
            "|      7|     6|   4.0|\n",
            "+-------+------+------+\n",
            "only showing top 10 rows\n",
            "\n",
            "==> Reading tiny1/tags.parquet\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- userId: integer (nullable = true)\n",
            " |-- tag: string (nullable = true)\n",
            "\n",
            "+-------+------+----------------+\n",
            "|movieId|userId|             tag|\n",
            "+-------+------+----------------+\n",
            "|      2|    62|         fantasy|\n",
            "|      2|    62|magic board game|\n",
            "|      2|    62|  Robin Williams|\n",
            "|      3|   289|           moldy|\n",
            "|      3|   289|             old|\n",
            "|      1|   336|           pixar|\n",
            "|      1|   474|           pixar|\n",
            "|      2|   474|            game|\n",
            "|      5|   474|       pregnancy|\n",
            "|      5|   474|          remake|\n",
            "+-------+------+----------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nmovies =  readParquet(DATASET + '/movies.parquet')\\nactors =  readParquet(DATASET + '/actors.parquet')\\ngenres =  readParquet(DATASET + '/genres.parquet')\\nratings = readParquet(DATASET + '/ratings.parquet')\\ntags =    readParquet(DATASET + '/tags.parquet')\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FRb5Gkjq1Sd",
        "colab_type": "text"
      },
      "source": [
        "## Calculate aggregate movie data\n",
        "\n",
        "The aim is to derive a data frame with the same data as __movies__, augmented\n",
        "with __numRatings__ and __avgRating__ columns, respectively representing the \n",
        "number of ratings and average rating per movie."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VbTISnIMe5NM",
        "colab_type": "code",
        "outputId": "e8f8e15c-34c3-4cd9-803b-423873967cd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "movies.createOrReplaceTempView('movies')\n",
        "ratings.createOrReplaceTempView('ratings')\n",
        "\n",
        "if DEBUG:\n",
        "  print(movies.count())\n",
        "  movies.printSchema()\n",
        "  movies.orderBy('movieId').show()\n",
        "\n",
        "ratings_agg = spark.sql(\n",
        "    '''\n",
        "    SELECT movieId,\n",
        "          COUNT(*) AS numRatings,\n",
        "          AVG(rating) AS avgRating\n",
        "    FROM ratings\n",
        "    GROUP BY movieId\n",
        "    '''\n",
        ")\n",
        "ratings_agg.createOrReplaceTempView('ratings_agg')\n",
        "\n",
        "if DEBUG:\n",
        "  print(ratings_agg.count())\n",
        "  ratings_agg.printSchema()\n",
        "  ratings_agg.orderBy('movieId').show()\n",
        "\n",
        "movies_agg = spark.sql(\n",
        "    '''\n",
        "    SELECT movieId, title, year, imdbId, \n",
        "           ifnull(numRatings, 0) as numRatings,\n",
        "           ifnull(avgRating, 0.0) as avgRating\n",
        "    FROM movies LEFT OUTER JOIN ratings_agg USING(movieId)\n",
        "    ORDER BY movieId\n",
        "    '''\n",
        ")\n",
        "if DEBUG:\n",
        "  print(movies_agg.count())\n",
        "  movies_agg.printSchema()\n",
        "  movies_agg.show()\n",
        "\n",
        "# no need for these, clean up\n",
        "spark.catalog.dropGlobalTempView('agg_ratings')\n",
        "spark.catalog.dropGlobalTempView('ratings')\n",
        "ratings.unpersist()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- imdbId: integer (nullable = true)\n",
            "\n",
            "+-------+--------------------+----+------+\n",
            "|movieId|               title|year|imdbId|\n",
            "+-------+--------------------+----+------+\n",
            "|      1|           Toy Story|1995|114709|\n",
            "|      2|             Jumanji|1995|113497|\n",
            "|      3|    Grumpier Old Men|1995|113228|\n",
            "|      4|   Waiting to Exhale|1995|114885|\n",
            "|      5|Father of the Bri...|1995|113041|\n",
            "|      6|                Heat|1995|113277|\n",
            "|      7|             Sabrina|1995|114319|\n",
            "|      8|        Tom and Huck|1995|112302|\n",
            "|      9|        Sudden Death|1995|114576|\n",
            "|     10|           GoldenEye|1995|113189|\n",
            "+-------+--------------------+----+------+\n",
            "\n",
            "10\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- numRatings: long (nullable = false)\n",
            " |-- avgRating: double (nullable = true)\n",
            "\n",
            "+-------+----------+------------------+\n",
            "|movieId|numRatings|         avgRating|\n",
            "+-------+----------+------------------+\n",
            "|      1|       215|3.9209302325581397|\n",
            "|      2|       110|3.4318181818181817|\n",
            "|      3|        52|3.2596153846153846|\n",
            "|      4|         7| 2.357142857142857|\n",
            "|      5|        49|3.0714285714285716|\n",
            "|      6|       102| 3.946078431372549|\n",
            "|      7|        54| 3.185185185185185|\n",
            "|      8|         8|             2.875|\n",
            "|      9|        16|             3.125|\n",
            "|     10|       132| 3.496212121212121|\n",
            "+-------+----------+------------------+\n",
            "\n",
            "10\n",
            "root\n",
            " |-- movieId: integer (nullable = true)\n",
            " |-- title: string (nullable = true)\n",
            " |-- year: integer (nullable = true)\n",
            " |-- imdbId: integer (nullable = true)\n",
            " |-- numRatings: long (nullable = false)\n",
            " |-- avgRating: double (nullable = false)\n",
            "\n",
            "+-------+--------------------+----+------+----------+------------------+\n",
            "|movieId|               title|year|imdbId|numRatings|         avgRating|\n",
            "+-------+--------------------+----+------+----------+------------------+\n",
            "|      1|           Toy Story|1995|114709|       215|3.9209302325581397|\n",
            "|      2|             Jumanji|1995|113497|       110|3.4318181818181817|\n",
            "|      3|    Grumpier Old Men|1995|113228|        52|3.2596153846153846|\n",
            "|      4|   Waiting to Exhale|1995|114885|         7| 2.357142857142857|\n",
            "|      5|Father of the Bri...|1995|113041|        49|3.0714285714285716|\n",
            "|      6|                Heat|1995|113277|       102| 3.946078431372549|\n",
            "|      7|             Sabrina|1995|114319|        54| 3.185185185185185|\n",
            "|      8|        Tom and Huck|1995|112302|         8|             2.875|\n",
            "|      9|        Sudden Death|1995|114576|        16|             3.125|\n",
            "|     10|           GoldenEye|1995|113189|       132| 3.496212121212121|\n",
            "+-------+--------------------+----+------+----------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DataFrame[movieId: int, userId: int, rating: double]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEJK69MtX4B2",
        "colab_type": "text"
      },
      "source": [
        "## Derive words for TF-IDF processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmGt0C93X7Lh",
        "colab_type": "code",
        "outputId": "b3b9474c-508b-4ef5-93a5-66fd075bcc13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        }
      },
      "source": [
        "from pyspark.sql import functions as F\n",
        "\n",
        "# Utility method to explode strings contained in the given field into a 'word' column\n",
        "def wordDf(df, field):\n",
        "  wdf = df.withColumn('word',\n",
        "                      F.explode(F.split(F.lower(F.col(field)),'[ \\s\\*\\+\\&\\/\\%\\-\\$\\#\\'\\)\\(\\[\\[\\],.!?;:\\t\\n\"]+'))).\\\n",
        "                      drop(field)\n",
        "\n",
        "  return wdf\n",
        "\n",
        "\n",
        "actor_words = wordDf(actors, 'name')\n",
        "genre_words = wordDf(genres,'genre')\n",
        "tag_words = wordDf(tags.drop('userId'), 'tag')\n",
        "title_words = wordDf(movies.select('movieId','title'), 'title')\n",
        "\n",
        "all_words = actor_words.union(genre_words)\\\n",
        "                       .union(tag_words)\\\n",
        "                       .union(title_words)\\\n",
        "                       \n",
        "if DEBUG:\n",
        "  print(all_words.count())\n",
        "  all_words.orderBy('movieId','word').show()\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "149\n",
            "+-------+---------+\n",
            "|movieId|     word|\n",
            "+-------+---------+\n",
            "|      1|adventure|\n",
            "|      1|    allen|\n",
            "|      1|animation|\n",
            "|      1| children|\n",
            "|      1|   comedy|\n",
            "|      1|      don|\n",
            "|      1|  fantasy|\n",
            "|      1|      fun|\n",
            "|      1|    hanks|\n",
            "|      1|      jim|\n",
            "|      1|    pixar|\n",
            "|      1|    pixar|\n",
            "|      1|  rickles|\n",
            "|      1|    story|\n",
            "|      1|      tim|\n",
            "|      1|      tom|\n",
            "|      1|      toy|\n",
            "|      1|   varney|\n",
            "|      2|adventure|\n",
            "|      2|    board|\n",
            "+-------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "f_kQzXOOIJVA"
      },
      "source": [
        "## Calculate TF-IDF metric (TODO)\n",
        "\n",
        "The aim is to derive a data frame with __(moviedId, word, tf_idf)__ values\n",
        "where the TF-IDF calculation is similar to the [one we discussed before during classes](https://colab.research.google.com/drive/15yMxBf1ltxrIaHCZUqqUWZBm6cqdcErF), i.e., the ${\\rm TFIDF}$ term we consider for a movie $m$ in the set of movies $M$ and word $w$ is given by\n",
        "   \n",
        "   $$\n",
        "   {\\rm TFIDF}(m,w) = {\\rm TF}(m,w) \\:\\times \\:{\\rm IDF}(w,M)\n",
        "   $$\n",
        "\n",
        "Only TF_IDF values equal or higher than the __MIN\\_TF_\\_IDF__ threshold should be written to the output files. The standard value to use for __MIN\\_TF_\\_IDF__ is  __0.1__ but you may adjust this value for testing purposes.\n",
        "\n",
        "\n",
        "__Important note__: you should __ONLY__ use the [Spark Data Frame API](https://spark.apache.org/docs/latest/api/python/pyspark.sql.html#pyspark.sql.DataFrame) and [Spark SQL](https://docs.databricks.com/spark/latest/spark-sql/language-manual/select.html) in your code (__NOT__ Pandas, any other Spark or generic Python libraries).\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXBvfoQD1S4-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Constants:\n",
        "  f = 'f'\n",
        "  f_max = 'f_max'\n",
        "  tf = 'TF'\n",
        "  n = 'n' \n",
        "  idf = 'IDF'\n",
        "  tf_idf = 'tfidf'\n",
        "  nr = 'nr'\n",
        "\n",
        "def show(debug, dataframe, message=None, rows=10):\n",
        "    if debug:\n",
        "        if message: \n",
        "          print(\"> %s (%d rows)\" % (message, dataframe.count()))\n",
        "        dataframe.show(rows)\n",
        "\n",
        "def get_idf(data, word='word', doc='doc', nr=None, debug=False):\n",
        "    \"\"\"Calculates the Inverse Document Frequency (IDF) of a DataFrame\n",
        "\n",
        "    Args:\n",
        "        data: A DataFrame instance.\n",
        "        word: Column word for 'word'\n",
        "        doc: Column name for 'documents'\n",
        "        nr: number of documents in which 'word' appears\n",
        "\n",
        "    Returns:\n",
        "        DataFrame ('word', 'IDF, [nr])\n",
        "    \"\"\"\n",
        "    n_w_D = data\\\n",
        "           .groupBy(word)\\\n",
        "           .agg(F.countDistinct(doc).alias('n_w_D'))\n",
        "    show(debug, n_w_D.orderBy('n_w_D',ascending=False))\n",
        "        \n",
        "    size_of_D = data.select(doc).distinct().count()\n",
        "    if debug: print(\"|D| = %d\" % size_of_D)\n",
        "    \n",
        "    IDF = n_w_D.withColumn(Constants.idf, F.log2(size_of_D / F.col('n_W_D')))\n",
        "    return IDF.withColumnRenamed('n_w_D', Constants.nr) if nr else IDF.drop('n_w_D')\n",
        "\n",
        "def tf_idf(data, word, doc, debug):\n",
        "    # f - nr of times word has been associated with doc by user\n",
        "    #           result -> (word, doc, Constants.f)\n",
        "    f = data.groupBy(word, doc)\\\n",
        "               .agg(F.count(doc).alias(Constants.f))\n",
        "    show(debug, f, \"group by ($word, $doc) count frequency done\")\n",
        "    # data.orderBy(word).show()\n",
        "    # f.orderBy(word).show()\n",
        "    \n",
        "    # f_max - maximum absolute frequency of any word used for doc\n",
        "    #         result -> (doc, Constants.f_max)\n",
        "    f_max = f.groupBy(doc)\\\n",
        "                   .agg(F.max(Constants.f).alias(Constants.f_max))\n",
        "    show(debug, f_max, \"Max frequency per movie done\")\n",
        "    \n",
        "    # call external function to calculate IDF\n",
        "    idf = get_idf(data, word, doc, Constants.nr, debug)\n",
        "    show(debug, idf, \"IDF done\")\n",
        "    \n",
        "    # join Constants.f_max on doc, calculate TF, join with IDF on word\n",
        "    df = f.join(f_max, doc)\\\n",
        "             .withColumn(Constants.tf, F.col(Constants.f) / F.col(Constants.f_max))\\\n",
        "             .join(idf, word)\n",
        "    show(debug, df, \"TF done\")\n",
        "    \n",
        "    # return dataframe with TF_IDF\n",
        "    return df.withColumn(Constants.tf_idf, df.TF * df.IDF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZjZBwN3jS-8",
        "colab_type": "code",
        "outputId": "18c31a8e-4a60-4ed5-f1fa-71301841b2af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "# Get TF-IDF for tags\n",
        "word = 'tag'\n",
        "wordFinal = 'word'\n",
        "doc = 'movieId'\n",
        "\n",
        "tfidf = tf_idf(tags, word, doc, False)\n",
        "tfidf.cache()\n",
        "\n",
        "# guarantee all columns are present\n",
        "tfidf = tfidf.drop(Constants.f)\\\n",
        "          .drop(Constants.f_max)\\\n",
        "          .drop(Constants.tf)\\\n",
        "          .drop(Constants.nr)\\\n",
        "          .drop(Constants.idf)\\\n",
        "          .withColumnRenamed(word, wordFinal)\n",
        "\n",
        "# assert tfidf.columns == [word, doc, Constants.f, Constants.f_max, Constants.tf, Constants.nr, Constants.idf, Constants.tf_idf],\\\n",
        "assert tfidf.columns == [wordFinal, doc, Constants.tf_idf],\\\n",
        "    \"Columns do not match expected values for tfidfTags\"\n",
        "# preview the dataframe\n",
        "tfidf.orderBy([Constants.f,Constants.tf_idf, doc,word], ascending=[0,0,1,1]).show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+----------------+-------+------------------+\n",
            "|            word|movieId|             tfidf|\n",
            "+----------------+-------+------------------+\n",
            "|           pixar|      1| 2.321928094887362|\n",
            "|  Robin Williams|      2| 2.321928094887362|\n",
            "|         fantasy|      2| 2.321928094887362|\n",
            "|            game|      2| 2.321928094887362|\n",
            "|magic board game|      2| 2.321928094887362|\n",
            "|           moldy|      3| 2.321928094887362|\n",
            "|             old|      3| 2.321928094887362|\n",
            "|       pregnancy|      5| 2.321928094887362|\n",
            "|          remake|      5|1.3219280948873624|\n",
            "|          remake|      7|1.3219280948873624|\n",
            "|             fun|      1| 1.160964047443681|\n",
            "+----------------+-------+------------------+\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZQpzAE9K9l9-",
        "colab_type": "text"
      },
      "source": [
        "## Movie similarity based on the Jaccard index (TODO for bonus grading)\n",
        "\n",
        "For every pair of movies $m_1$ and $m_2$ compute a similary ratio based on the __Jaccard index__: \n",
        "\n",
        "  $$\n",
        "  {\\rm JI}(m_1, m_2) =  \\frac{| {\\rm urt}(m_1) \\cap {\\rm urt}(m_2)|}{ |{\\rm urt}(m_1) \\cup {\\rm urt}(m_2)|}   \n",
        "  $$\n",
        "\n",
        "where ${\\rm urt}(m)$ is defined as the set of users who have tagged or rated a movie $m$.\n",
        "\n",
        "For further reference on the Jaccard index metric see:\n",
        "\n",
        "  - [Mining of Massive Data Sets, sec. 3.3.1](http://infolab.stanford.edu/%7Eullman/mmds/book.pdf)\n",
        "  - [Wikipedia page for the Jaccard Index](https://en.wikipedia.org/wiki/Jaccard_index)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7xLGy7TCW_hz",
        "colab_type": "text"
      },
      "source": [
        "Calculates the Jaccard index to measure similarity between movies based on user ratings.\n",
        "\n",
        "Linking a movie means rating >= 4.0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdvDfhozHnMx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "dc788cfb-c73b-4f62-8cd4-1cf3de1128c6"
      },
      "source": [
        "def jaccard_index(df1, df2, column=\"user\", sort=\"movie\"):\n",
        "    # sort    - prefix of the columns to sort\n",
        "    # column  - prefix of the columns to use as sets\n",
        "    \n",
        "    # 1. product - cross join to get movie1, movie2\n",
        "    # 2. count intersect set\n",
        "    # 3. count union set\n",
        "    # 4. calculate Jaccard Index\n",
        "    # 5. remove unwanted columns\n",
        "    users = [column + \"1\", column + \"2\"]\n",
        "    sorts = [\"%s1\" % (sort), \"%s2\" % (sort)]\n",
        "    df1 = df1.crossJoin(df2)\\\n",
        "              .filter(\"%s < %s\" % (sorts[0], sorts[1]))\n",
        "    df1 = df1.withColumn(\"user\", F.size(F.array_union(users[0], users[1])))\\\n",
        "              .withColumn(\"index\", F.size(F.array_intersect(users[0], users[1])))\\\n",
        "              .withColumn(\"jaccard_index\", F.col(\"index\")/F.col(\"user\"))\n",
        "    return df1.drop(users[0], users[1])\n",
        "              \n",
        "def movieSimilarity(ratings, minRatings=10, threshold=4.0, debug=False):\n",
        "\n",
        "    ratings = ratings.filter(\"rating >= %i\" % (threshold))\n",
        "    \n",
        "    ratings=ratings.drop(\"rating\")\n",
        "    show(debug, ratings, \"like's dataframe\")\n",
        "        \n",
        "    # filter movies with less than minRatings ratings\n",
        "    # obtain set of users that LIKED a given movie\n",
        "    df_m1 = ratings.groupBy(\"movieId\")\\\n",
        "                    .agg(F.collect_set(ratings.userId).alias(\"user1\"))\\\n",
        "                    .withColumnRenamed(\"movieId\", \"movie1\")\\\n",
        "                    .filter(minRatings < F.size(\"user1\"))\n",
        "    show(debug, df_m1, \"movie with users that liked it\")\n",
        "        \n",
        "    # duplicate dataframe for cross join\n",
        "    df_m2 = df_m1.withColumnRenamed(\"user1\", \"user2\")\\\n",
        "                 .withColumnRenamed(\"movie1\", \"movie2\")\n",
        "    show(debug, df_m2, \"movie with users that liked it - copy renamed\")\n",
        "        \n",
        "    return jaccard_index(df_m1, df_m2) \n",
        "\n",
        "ji = movieSimilarity(ratings).orderBy(['index','jaccard_index','movie1','movie2'], ascending=[0,0,1,1])\n",
        "assert ji.columns == [\"movie1\", \"movie2\", \"user\", \"index\", \"jaccard_index\"], \"unexpected column value\"\n",
        "ji.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+------+------+----+-----+--------------------+\n",
            "|movie1|movie2|user|index|       jaccard_index|\n",
            "+------+------+----+-----+--------------------+\n",
            "|     1|     6| 189|   27| 0.14285714285714285|\n",
            "|     1|     2| 176|   21| 0.11931818181818182|\n",
            "|     1|    10| 187|   19| 0.10160427807486631|\n",
            "|     6|    10| 117|   11| 0.09401709401709402|\n",
            "|     1|     3| 154|   11| 0.07142857142857142|\n",
            "|     2|    10| 100|    9|                0.09|\n",
            "|     2|     6| 111|    8| 0.07207207207207207|\n",
            "|     1|     5| 152|    7|0.046052631578947366|\n",
            "|     1|     7| 160|    7|             0.04375|\n",
            "|     2|     7|  64|    6|             0.09375|\n",
            "|     3|     7|  33|    5| 0.15151515151515152|\n",
            "|     2|     3|  63|    5| 0.07936507936507936|\n",
            "|     7|    10|  74|    5| 0.06756756756756757|\n",
            "|     3|     5|  26|    4| 0.15384615384615385|\n",
            "|     5|     7|  28|    4| 0.14285714285714285|\n",
            "|     2|     5|  58|    4| 0.06896551724137931|\n",
            "|     3|     6|  83|    4| 0.04819277108433735|\n",
            "|     3|    10|  74|    3| 0.04054054054054054|\n",
            "|     5|     6|  78|    3|0.038461538461538464|\n",
            "|     5|    10|  69|    2|0.028985507246376812|\n",
            "+------+------+----+-----+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2L6Z9EdPbjkv",
        "colab_type": "text"
      },
      "source": [
        "## Write output data to Parquet files and generate ZIP file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyST7eVyVlXt",
        "colab_type": "code",
        "outputId": "75bf2097-e2cf-4549-8864-c09b583c0b05",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        }
      },
      "source": [
        "# Clean up first\n",
        "!rm -fr \"$DATASET\"/output \n",
        "!rm -f \"$DATASET\"/\"$OUTPUT_ZIP_FILE\"\n",
        "\n",
        "if DEBUG:\n",
        "  !ls -l $DATASET\n",
        "\n",
        "writeParquet(movies_agg, DATASET + '/output/' + 'movies_agg.parquet')\n",
        "writeParquet(tfidf, DATASET + '/output/' + 'tfidf.parquet')\n",
        "# bonus\n",
        "writeParquet(ji, DATASET + '/output/' + 'jaccardIndex.parquet')\n",
        "\n",
        "if DEBUG:\n",
        "  print('Creating ZIP file ...')\n",
        "\n",
        "!cd \"$DATASET\"/output  && zip -9qr ../\"$OUTPUT_ZIP_FILE\" .\n",
        "\n",
        "if DEBUG:\n",
        "  !ls -l $DATASET \"$DATASET\"/output\n",
        " "
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 20\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 14:08 actors.parquet\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 14:08 genres.parquet\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 14:08 movies.parquet\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 14:08 ratings.parquet\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 14:08 tags.parquet\n",
            "==> Writing tiny1/output/movies_agg.parquet\n",
            "==> Writing tiny1/output/tfidf.parquet\n",
            "==> Writing tiny1/output/jaccardIndex.parquet\n",
            "Creating ZIP file ...\n",
            "tiny1:\n",
            "total 76\n",
            "drwxr-xr-x 2 root root  4096 Apr  3 14:08 actors.parquet\n",
            "drwxr-xr-x 2 root root  4096 Apr  3 14:08 genres.parquet\n",
            "drwxr-xr-x 2 root root  4096 Apr  3 14:08 movies.parquet\n",
            "drwxr-xr-x 5 root root  4096 Apr  3 17:48 output\n",
            "-rw-r--r-- 1 root root 51340 Apr  3 17:49 output.zip\n",
            "drwxr-xr-x 2 root root  4096 Apr  3 14:08 ratings.parquet\n",
            "drwxr-xr-x 2 root root  4096 Apr  3 14:08 tags.parquet\n",
            "\n",
            "tiny1/output:\n",
            "total 12\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 17:48 jaccardIndex.parquet\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 17:48 movies_agg.parquet\n",
            "drwxr-xr-x 2 root root 4096 Apr  3 17:48 tfidf.parquet\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BZ3e-2m1G4k",
        "colab_type": "text"
      },
      "source": [
        "## Copy output ZIP file to output bucket"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oG2umQ870TZ3",
        "colab_type": "code",
        "outputId": "4698ba3d-f03c-4495-92e4-8ff27f8950be",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "! gsutil cp $DATASET/output.zip gs://\"$OUTPUT_BUCKET\"/\"$DATASET\"/output.zip "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://tiny1/output.zip [Content-Type=application/zip]...\n",
            "/ [1 files][ 50.1 KiB/ 50.1 KiB]                                                \n",
            "Operation completed over 1 objects/50.1 KiB.                                     \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcCm38U9w8_h",
        "colab_type": "text"
      },
      "source": [
        "## Copy Parquet files to output bucket (optional)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Mk_2_abxKTm",
        "colab_type": "code",
        "outputId": "acb858a5-3310-4a5a-ca5a-8b88f9be06d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "if COPY_PARQUET_FILES_TO_OUTPUT_BUCKET:\n",
        "  ! gsutil -m cp -r $DATASET/output/movies_agg.parquet gs://\"$OUTPUT_BUCKET\"/\"$DATASET\"/\n",
        "  ! gsutil -m cp -r $DATASET/output/tfidf.parquet gs://\"$OUTPUT_BUCKET\"/\"$DATASET\"/\n",
        "  ! gsutil -m cp -r $DATASET/output/jaccardIndex.parquet gs://\"$OUTPUT_BUCKET\"/\"$DATASET\"/"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Copying file://tiny1/output/movies_agg.parquet/part-00000-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/_SUCCESS [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/.part-00001-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \r/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/.part-00006-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/.part-00008-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/part-00009-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/part-00005-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/part-00008-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "/ [0/22 files][    0.0 B/ 15.9 KiB]   0% Done                                   \rCopying file://tiny1/output/movies_agg.parquet/.part-00005-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/.part-00004-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/.part-00002-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/part-00001-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/.part-00007-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/._SUCCESS.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/part-00007-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/.part-00003-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/.part-00009-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/part-00002-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/part-00003-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/part-00006-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/.part-00000-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/movies_agg.parquet/part-00004-1fba380d-3923-43ee-a216-c68e41b41394-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "- [22/22 files][ 15.9 KiB/ 15.9 KiB] 100% Done                                  \n",
            "Operation completed over 22 objects/15.9 KiB.                                    \n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00000-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/_SUCCESS [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00183-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00074-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00114-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00123-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00115-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00130-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00123-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00022-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00074-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00107-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00107-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00183-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00022-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00000-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/._SUCCESS.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00004-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00115-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00004-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00130-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00133-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00114-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00133-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/.part-00150-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/tfidf.parquet/part-00150-75a63e30-2d63-456f-93b4-1f351c2401c2-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "- [26/26 files][ 10.2 KiB/ 10.2 KiB] 100% Done                                  \n",
            "Operation completed over 26 objects/10.2 KiB.                                    \n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00011-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00003-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00001-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00004-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00020-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00013-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/_SUCCESS [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00017-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00007-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00010-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00014-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00018-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00020-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00011-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00016-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00009-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00000-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00004-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00019-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00010-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00012-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00012-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00002-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00006-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/._SUCCESS.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00019-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00015-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00015-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00008-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00008-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00002-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00006-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00000-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00007-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00017-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00013-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00014-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00001-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00005-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00009-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00018-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00003-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/part-00005-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet [Content-Type=application/octet-stream]...\n",
            "Copying file://tiny1/output/jaccardIndex.parquet/.part-00016-7943755a-5056-4b8c-b832-9759650ef837-c000.snappy.parquet.crc [Content-Type=application/octet-stream]...\n",
            "\\ [44/44 files][ 26.5 KiB/ 26.5 KiB] 100% Done                                  \n",
            "Operation completed over 44 objects/26.5 KiB.                                    \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJbP3yLDCTgx",
        "colab_type": "text"
      },
      "source": [
        "## Send PubSub cloud message "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WDJ1dt_5CdJh",
        "colab_type": "text"
      },
      "source": [
        "This will trigger the LCF cloud function. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5GwFGmV5QF4",
        "colab_type": "code",
        "outputId": "991cf1be-d58d-4099-c7d0-2703f30dc8bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "if SEND_PUBSUB_MESSAGE:\n",
        " !gcloud pubsub topics publish $PUBSUB_TOPIC --message $DATASET"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "messageIds:\n",
            "- '1112573012219345'\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}